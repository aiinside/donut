{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import basename\n",
    "from pathlib import Path\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
    "from pytorch_lightning.plugins import CheckpointIO\n",
    "from pytorch_lightning.utilities import rank_zero_only\n",
    "from sconf import Config\n",
    "import PIL.Image\n",
    "\n",
    "# from donut import DonutModel, DonutConfig\n",
    "import donut.model_custom\n",
    "from donut.model_custom import DonutModel, DonutConfig, BARTCustomTokenizer\n",
    "from donut import DonutDataset\n",
    "from lightning_module import DonutDataPLModule, DonutModelPLModule\n",
    "\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLMRobertaTokenizer'. \n",
      "The class this function is called from is 'BARTCustomTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "config_path='/data/murayama/k8s/ocr_dxs1/donut/config/test_health_box.yaml'\n",
    "config=Config(config_path)\n",
    "model = DonutModel.from_pretrained(\n",
    "    config.pretrained_model_name_or_path,\n",
    "    input_size=config.input_size,\n",
    "    max_length=config.max_length,\n",
    "    align_long_axis=config.align_long_axis,\n",
    "    enable_char_map=config.char_map,\n",
    "    box_pred=config.get('box_pred',False)\n",
    ")\n",
    "\n",
    "if 'classes' in config:\n",
    "    stokens = []\n",
    "    for cn in config.classes:\n",
    "        stokens += [fr\"<s_{cn}>\", fr\"</s_{cn}>\"]\n",
    "    model.decoder.add_special_tokens(stokens)\n",
    "\n",
    "model = model.cuda().half().eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path='/data/murayama/k8s/ocr_dxs1/dxsx-atypical-engine/data/vhr_testdata_64_focr/testdata_2021/G49-2021-000442-001.jpg'\n",
    "image=PIL.Image.open(image_path)\n",
    "# outs = model.inference(image, prompt='<s_health>', return_attentions=True, return_confs=True, return_tokens=True)\n",
    "try:\n",
    "    outs = model.inference(image, prompt='<s_health><s_health>', return_attentions=True, return_segmap=False, return_confs=True, return_tokens=True, token_score_thresh=0.45)\n",
    "except Exception as ex:\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'bmi_0': ['20.5', 1.0, [2, 3]]},\n",
       "  {'bmi_1': ['20.8', 1.0, [7, 8]]},\n",
       "  {'bmi_2': ['20.8', 0.99951171875, [12, 13]]},\n",
       "  {'bp_diastolic_0': ['66', 1.0, [17]]},\n",
       "  {'bp_diastolic_1': ['70', 1.0, [21]]},\n",
       "  {'bp_diastolic_2': ['48', 1.0, [25]]},\n",
       "  {'bp_diastolic_2_0': ['55', 1.0, [29]]},\n",
       "  {'bp_diastolic_2_1': ['60', 0.9990234375, [33]]},\n",
       "  {'bp_systolic_0': ['102', 1.0, [37]]},\n",
       "  {'bp_systolic_1': ['104', 1.0, [41]]},\n",
       "  {'bp_systolic_2': ['84', 0.99951171875, [45]]},\n",
       "  {'bp_systolic_2_0': ['96', 1.0, [49]]},\n",
       "  {'bp_systolic_2_1': ['108', 0.99951171875, [53]]},\n",
       "  {'btype_abo_0': ['B', 0.99853515625, [57]]},\n",
       "  {'btype_abo_1': ['B', 1.0, [61]]},\n",
       "  {'btype_abo_2': ['B', 1.0, [65]]},\n",
       "  {'btype_rh_0': ['+', 0.99853515625, [69]]},\n",
       "  {'btype_rh_1': ['+', 1.0, [73]]},\n",
       "  {'btype_rh_2': ['+', 1.0, [77]]},\n",
       "  {'ecg_rest_0': ['異常所見なし', 0.9995930989583334, [82, 83, 84, 85, 86, 87]]},\n",
       "  {'ecg_rest_1': ['異常所見なし', 0.9998372395833334, [91, 92, 93, 94, 95, 96]]},\n",
       "  {'ecg_rest_2': ['異常所見なし',\n",
       "    0.9999186197916666,\n",
       "    [100, 101, 102, 103, 104, 105]]},\n",
       "  {'exam_date_0': ['2021/05/13', 1.0, [109, 110, 111, 112]]},\n",
       "  {'exam_date_0': ['021/05/13', 1.0, [116, 117, 118, 119]]},\n",
       "  {'exam_date_0': ['021/05/13', 0.9998779296875, [123, 124, 125, 126]]},\n",
       "  {'exam_date_0': ['021/05/13', 0.999267578125, [130, 131, 132, 133]]},\n",
       "  {'exam_date_1': ['2020/09/17', 0.99853515625, [137, 138, 139]]},\n",
       "  {'exam_date_1': ['2020/09/17', 1.0, [143, 144, 145]]},\n",
       "  {'exam_date_2': ['2019/11/20', 1.0, [149, 150, 151]]},\n",
       "  {'exam_date_2': ['2019/11/20', 1.0, [155, 156, 157]]},\n",
       "  {'examinee_name_0': ['鳥梨彩子', 0.93447265625, [161, 162, 163, 164, 165]]},\n",
       "  {'exmaminee_dob_0': ['1980/04/07', 0.9994140625, [171]]},\n",
       "  {'eye_sight_l_0': ['1.5', 1.0, [179]]},\n",
       "  {'eye_sight_l_1': ['1.5', 0.99951171875, [183]]},\n",
       "  {'eye_sight_l_2': ['1.5', 0.99951171875, [187]]},\n",
       "  {'eye_sight_r_0': ['1.5', 0.99951171875, [191]]},\n",
       "  {'eye_sight_r_1': ['1.0', 0.9970703125, [195]]},\n",
       "  {'eye_sight_r_2': ['1.5', 1.0, [199]]},\n",
       "  {'eyeground_fr_0': ['異常所見なし', 0.9998372395833334, [203]]},\n",
       "  {'eyeground_fr_1': ['異常所見なし', 0.999755859375, [212]]},\n",
       "  {'eyeground_fr_2': ['異常所見なし', 0.9999186197916666, [221]]},\n",
       "  {'hearing_1000_l_0': ['異常なし', 1.0, [230]]},\n",
       "  {'hearing_1000_l_1': ['異常なし', 0.99951171875, [237]]},\n",
       "  {'hearing_1000_l_2': ['異常なし', 0.999267578125, [244]]},\n",
       "  {'hearing_1000_r_0': ['異常なし', 1.0, [251]]},\n",
       "  {'hearing_1000_r_1': ['異常なし', 0.9996337890625, [258]]},\n",
       "  {'hearing_1000_r_2': ['異常なし', 0.999755859375, [265]]},\n",
       "  {'hearing_4000_l_0': ['異常なし', 0.9998779296875, [272]]},\n",
       "  {'hearing_4000_l_1': ['異常なし', 0.9996337890625, [279]]},\n",
       "  {'hearing_4000_l_2': ['異常なし', 0.9937744140625, [286]]},\n",
       "  {'hearing_4000_r_0': ['異常なし', 0.9993896484375, [293]]},\n",
       "  {'hearing_4000_r_1': ['異常なし', 0.9996337890625, [300]]},\n",
       "  {'hearing_4000_r_2': ['異常なし', 0.99951171875, [307]]},\n",
       "  {'height_0': ['158.5', 1.0, [314]]},\n",
       "  {'height_1': ['158.5', 1.0, [320]]},\n",
       "  {'height_2': ['158.2', 1.0, [326]]},\n",
       "  {'iop_l_0': ['17', 0.99951171875, [332]]},\n",
       "  {'iop_l_1': ['13', 1.0, [336]]},\n",
       "  {'iop_l_2': ['16', 1.0, [340]]},\n",
       "  {'iop_r_0': ['16', 1.0, [344]]},\n",
       "  {'iop_r_1': ['15', 0.99951171875, [348]]},\n",
       "  {'iop_r_2': ['14', 1.0, [352]]},\n",
       "  {'medical_finding_0': ['異常所見なし', 0.9991861979166666, [356]]},\n",
       "  {'medical_finding_1': ['異常所見なし', 1.0, [365]]},\n",
       "  {'medical_finding_2': ['異常所見なし', 1.0, [374]]},\n",
       "  {'medical_history_0': ['特になし', 1.0, [383]]},\n",
       "  {'medical_history_0': ['特になし', 1.0, [389]]},\n",
       "  {'std_weight_0': ['55.3', 0.99560546875, [399]]},\n",
       "  {'std_weight_1': ['55.3', 0.9998372395833334, [405]]},\n",
       "  {'std_weight_2': ['55.12', 0.87939453125, [411]]},\n",
       "  {'total_diagnosis_0': ['血圧が低いです。立ちくらみなど症状があれば御環器内科を受診してください。A/G比(肝機能)が高めですが問題ありません。逆流性食道炎が認められます。症状がありましたら治療を受けてください。胃に胃炎の変化が認められますが心配ありません。I年後再検査を受けてください。胆のうポリープが認められます。I年後経過観察を受けてください。',\n",
       "    0.9958224826388888,\n",
       "    [417]]},\n",
       "  {'waist_0': ['75.4', 0.9998372395833334, [546]]},\n",
       "  {'waist_1': ['79.5', 1.0, [552]]},\n",
       "  {'waist_2': ['78.3', 0.99951171875, [558]]},\n",
       "  {'weight_0': ['51.5', 0.999267578125, [564]]},\n",
       "  {'weight_1': ['52.2', 0.998779296875, [569]]},\n",
       "  {'weight_2': ['52.0', 0.998291015625, [574]]}]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs[\"predictions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3326592/2793405743.py:7: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  boxes = boxes.detach().cpu().numpy().astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "decoder_states = [ds[-1] for ds in outs[\"decoder_state\"]]\n",
    "decoder_states = torch.cat(decoder_states, dim=1)\n",
    "_, boxes, confs = model.forward_box_head(decoder_states)\n",
    "box_mask = outs['tokens'][:,1:] > model.decoder.tokenizer.vocab_size\n",
    "#boxes = boxes[box_mask][1::2]\n",
    "boxes *= 1600\n",
    "boxes = boxes.detach().cpu().numpy().astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(58397, device='cuda:0') 0.9892578125 tensor(0.2440, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1109 684 1145 706\n",
      "tensor(57553, device='cuda:0') 1.0 tensor(0.5596, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1130 678 1158 692\n",
      "tensor(58398, device='cuda:0') 1.0 tensor(0.5044, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1313 678 1341 692\n",
      "tensor(57554, device='cuda:0') 1.0 tensor(0.5679, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1311 678 1339 694\n",
      "tensor(58399, device='cuda:0') 1.0 tensor(0.5269, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1456 677 1486 693\n",
      "tensor(57555, device='cuda:0') 0.9951171875 tensor(0.5591, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1455 677 1481 693\n",
      "tensor(58403, device='cuda:0') 0.95654296875 tensor(0.4392, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1137 811 1159 827\n",
      "tensor(57559, device='cuda:0') 1.0 tensor(0.5010, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1136 812 1158 826\n",
      "tensor(58404, device='cuda:0') 1.0 tensor(0.4854, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1312 814 1334 830\n",
      "tensor(57560, device='cuda:0') 1.0 tensor(0.4963, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1311 813 1331 827\n",
      "tensor(58405, device='cuda:0') 0.99951171875 tensor(0.4434, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1460 811 1480 827\n",
      "tensor(57561, device='cuda:0') 1.0 tensor(0.4736, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1461 812 1481 828\n",
      "tensor(58406, device='cuda:0') 1.0 tensor(0.3401, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1135 842 1161 860\n",
      "tensor(57562, device='cuda:0') 1.0 tensor(0.4854, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1136 844 1156 858\n",
      "tensor(58407, device='cuda:0') 1.0 tensor(0.4880, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1312 839 1332 855\n",
      "tensor(57563, device='cuda:0') 1.0 tensor(0.5303, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1309 844 1329 858\n",
      "tensor(58409, device='cuda:0') 1.0 tensor(0.3560, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1132 797 1158 815\n",
      "tensor(57565, device='cuda:0') 1.0 tensor(0.5454, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1136 799 1160 813\n",
      "tensor(58410, device='cuda:0') 1.0 tensor(0.5308, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1309 797 1331 813\n",
      "tensor(57566, device='cuda:0') 1.0 tensor(0.5493, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1308 796 1332 812\n",
      "tensor(58411, device='cuda:0') 0.99951171875 tensor(0.4739, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1464 798 1486 814\n",
      "tensor(57567, device='cuda:0') 1.0 tensor(0.4976, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1463 797 1483 813\n",
      "tensor(58412, device='cuda:0') 1.0 tensor(0.4995, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1131 827 1151 843\n",
      "tensor(57568, device='cuda:0') 1.0 tensor(0.5137, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1135 829 1155 843\n",
      "tensor(58413, device='cuda:0') 1.0 tensor(0.5342, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1310 832 1334 846\n",
      "tensor(57569, device='cuda:0') 1.0 tensor(0.5596, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1308 829 1332 845\n",
      "tensor(58424, device='cuda:0') 1.0 tensor(0.1268, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1150 718 1188 736\n",
      "tensor(57580, device='cuda:0') 1.0 tensor(0.3601, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1124 724 1148 740\n",
      "tensor(58425, device='cuda:0') 1.0 tensor(0.3403, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1318 722 1348 738\n",
      "tensor(57581, device='cuda:0') 1.0 tensor(0.3696, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1368 724 1400 742\n",
      "tensor(58426, device='cuda:0') 1.0 tensor(0.3303, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1497 727 1527 747\n",
      "tensor(57582, device='cuda:0') 1.0 tensor(0.3557, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1468 720 1506 742\n",
      "tensor(58427, device='cuda:0') 0.998046875 tensor(0.3577, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1182 727 1210 747\n",
      "tensor(57583, device='cuda:0') 1.0 tensor(0.3884, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1183 729 1205 745\n",
      "tensor(58428, device='cuda:0') 1.0 tensor(0.3035, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1364 728 1398 750\n",
      "tensor(57584, device='cuda:0') 1.0 tensor(0.3699, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1374 731 1400 749\n",
      "tensor(58429, device='cuda:0') 0.99951171875 tensor(0.4219, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1505 731 1537 751\n",
      "tensor(57585, device='cuda:0') 1.0 tensor(0.2783, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1509 724 1537 746\n",
      "tensor(58601, device='cuda:0') 1.0 tensor(0.0536, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 749 317 829 343\n",
      "tensor(57757, device='cuda:0') 1.0 tensor(0.6221, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1011 911 1099 927\n",
      "tensor(58602, device='cuda:0') 1.0 tensor(0.6260, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1210 912 1292 930\n",
      "tensor(57758, device='cuda:0') 1.0 tensor(0.6743, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1212 913 1290 931\n",
      "tensor(58603, device='cuda:0') 1.0 tensor(0.6064, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1389 907 1477 929\n",
      "tensor(57759, device='cuda:0') 1.0 tensor(0.6367, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1395 910 1471 928\n",
      "tensor(58625, device='cuda:0') 1.0 tensor(0.2549, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 828 310 908 328\n",
      "tensor(57781, device='cuda:0') 1.0 tensor(0.5596, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 758 311 826 325\n",
      "tensor(58625, device='cuda:0') 0.50341796875 tensor(0.2397, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1475 307 1527 325\n",
      "tensor(57781, device='cuda:0') 1.0 tensor(0.0115, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1048 554 1142 576\n",
      "tensor(58625, device='cuda:0') 0.98388671875 tensor(0.0025, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1170 608 1262 626\n",
      "tensor(57781, device='cuda:0') 1.0 tensor(0.0186, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1154 690 1238 712\n",
      "tensor(58625, device='cuda:0') 0.91357421875 tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1145 770 1233 786\n",
      "tensor(57781, device='cuda:0') 1.0 tensor(0.0866, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1143 799 1223 819\n",
      "tensor(58626, device='cuda:0') 0.80712890625 tensor(0.0022, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1221 822 1309 838\n",
      "tensor(57782, device='cuda:0') 1.0 tensor(0.3264, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1338 657 1406 675\n",
      "tensor(58626, device='cuda:0') 0.87451171875 tensor(0.0423, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1389 779 1451 801\n",
      "tensor(57782, device='cuda:0') 1.0 tensor(0.1142, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1316 852 1378 870\n",
      "tensor(58627, device='cuda:0') 0.9658203125 tensor(0.0239, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1472 830 1532 856\n",
      "tensor(57783, device='cuda:0') 1.0 tensor(0.1027, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1466 592 1530 616\n",
      "tensor(58627, device='cuda:0') 0.5146484375 tensor(0.0640, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1479 802 1535 824\n",
      "tensor(57783, device='cuda:0') 1.0 tensor(0.0914, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1468 886 1536 910\n",
      "tensor(58631, device='cuda:0') 1.0 tensor(0.5850, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 243 323 311 339\n",
      "tensor(57787, device='cuda:0') 1.0 tensor(0.6523, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 246 326 314 342\n",
      "tensor(58631, device='cuda:0') 1.0 tensor(0.4653, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1022 334 1098 350\n",
      "tensor(58637, device='cuda:0') 1.0 tensor(0.3567, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 819 319 901 333\n",
      "tensor(57793, device='cuda:0') 1.0 tensor(0.6074, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 462 324 518 338\n",
      "tensor(58646, device='cuda:0') 0.99951171875 tensor(0.4788, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1132 1045 1158 1059\n",
      "tensor(57802, device='cuda:0') 1.0 tensor(0.5249, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1134 1045 1156 1059\n",
      "tensor(58647, device='cuda:0') 0.9990234375 tensor(0.4998, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1311 1044 1335 1058\n",
      "tensor(57803, device='cuda:0') 1.0 tensor(0.5044, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1311 1042 1335 1058\n",
      "tensor(58648, device='cuda:0') 0.85107421875 tensor(0.4893, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1454 1040 1478 1056\n",
      "tensor(57804, device='cuda:0') 1.0 tensor(0.5024, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1456 1044 1478 1060\n",
      "tensor(58649, device='cuda:0') 0.9990234375 tensor(0.5181, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1133 1024 1157 1038\n",
      "tensor(57805, device='cuda:0') 1.0 tensor(0.5210, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1132 1026 1156 1040\n",
      "tensor(58650, device='cuda:0') 1.0 tensor(0.5190, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1309 1026 1331 1042\n",
      "tensor(57806, device='cuda:0') 1.0 tensor(0.5273, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1310 1024 1332 1040\n",
      "tensor(58651, device='cuda:0') 1.0 tensor(0.4961, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1458 1025 1480 1043\n",
      "tensor(57807, device='cuda:0') 1.0 tensor(0.5078, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1458 1029 1480 1045\n",
      "tensor(58655, device='cuda:0') 1.0 tensor(0.5830, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1097 1124 1167 1144\n",
      "tensor(57811, device='cuda:0') 1.0 tensor(0.6431, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1091 1126 1167 1144\n",
      "tensor(58656, device='cuda:0') 1.0 tensor(0.6230, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1277 1128 1349 1148\n",
      "tensor(57812, device='cuda:0') 1.0 tensor(0.6299, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1278 1127 1346 1145\n",
      "tensor(58657, device='cuda:0') 0.99951171875 tensor(0.5933, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1420 1126 1490 1148\n",
      "tensor(57813, device='cuda:0') 1.0 tensor(0.6011, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1420 1131 1490 1151\n",
      "tensor(58701, device='cuda:0') 1.0 tensor(0.4961, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1115 1241 1161 1263\n",
      "tensor(57857, device='cuda:0') 1.0 tensor(0.5894, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1116 1243 1166 1259\n",
      "tensor(58702, device='cuda:0') 1.0 tensor(0.5645, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1295 1241 1347 1259\n",
      "tensor(57858, device='cuda:0') 1.0 tensor(0.5337, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1298 1238 1348 1256\n",
      "tensor(58703, device='cuda:0') 0.99658203125 tensor(0.5317, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1446 1237 1494 1257\n",
      "tensor(57859, device='cuda:0') 1.0 tensor(0.5259, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1444 1238 1496 1256\n",
      "tensor(58704, device='cuda:0') 1.0 tensor(0.5728, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1116 1227 1170 1245\n",
      "tensor(57860, device='cuda:0') 1.0 tensor(0.5811, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1117 1226 1171 1244\n",
      "tensor(58705, device='cuda:0') 1.0 tensor(0.5415, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1301 1225 1347 1243\n",
      "tensor(57861, device='cuda:0') 1.0 tensor(0.5649, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1298 1226 1350 1244\n",
      "tensor(58706, device='cuda:0') 0.99951171875 tensor(0.5171, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1447 1227 1493 1247\n",
      "tensor(57862, device='cuda:0') 1.0 tensor(0.5376, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1444 1226 1492 1244\n",
      "tensor(58713, device='cuda:0') 0.99951171875 tensor(0.5718, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1119 1278 1171 1294\n",
      "tensor(57869, device='cuda:0') 1.0 tensor(0.5830, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1121 1275 1173 1291\n",
      "tensor(58714, device='cuda:0') 0.98095703125 tensor(0.5566, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1290 1276 1344 1294\n",
      "tensor(57870, device='cuda:0') 1.0 tensor(0.5762, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1292 1275 1346 1293\n",
      "tensor(58715, device='cuda:0') 0.99951171875 tensor(0.5396, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1440 1274 1496 1294\n",
      "tensor(57871, device='cuda:0') 1.0 tensor(0.5410, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1440 1274 1494 1292\n",
      "tensor(58716, device='cuda:0') 1.0 tensor(0.6162, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1110 1258 1166 1276\n",
      "tensor(57872, device='cuda:0') 1.0 tensor(0.6265, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1112 1257 1168 1275\n",
      "tensor(58717, device='cuda:0') 1.0 tensor(0.5850, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1292 1254 1348 1272\n",
      "tensor(57873, device='cuda:0') 1.0 tensor(0.5806, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1295 1253 1351 1271\n",
      "tensor(58718, device='cuda:0') 1.0 tensor(0.5474, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1437 1256 1491 1278\n",
      "tensor(57874, device='cuda:0') 1.0 tensor(0.5259, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1440 1256 1492 1276\n",
      "tensor(58731, device='cuda:0') 0.99951171875 tensor(0.5884, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1128 628 1162 644\n",
      "tensor(57887, device='cuda:0') 1.0 tensor(0.6011, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1128 629 1162 643\n",
      "tensor(58732, device='cuda:0') 1.0 tensor(0.5840, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1310 630 1346 646\n",
      "tensor(57888, device='cuda:0') 1.0 tensor(0.5986, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1311 630 1345 646\n",
      "tensor(58733, device='cuda:0') 1.0 tensor(0.5518, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1454 632 1486 648\n",
      "tensor(57889, device='cuda:0') 1.0 tensor(0.5898, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1452 630 1486 646\n",
      "tensor(58797, device='cuda:0') 1.0 tensor(0.0370, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1115 1101 1195 1127\n",
      "tensor(57953, device='cuda:0') 1.0 tensor(0.4790, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1132 1110 1156 1126\n",
      "tensor(58798, device='cuda:0') 1.0 tensor(0.4717, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1309 1112 1333 1128\n",
      "tensor(57954, device='cuda:0') 1.0 tensor(0.4819, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1310 1110 1334 1126\n",
      "tensor(58799, device='cuda:0') 0.99658203125 tensor(0.4724, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1459 1114 1481 1132\n",
      "tensor(57955, device='cuda:0') 1.0 tensor(0.4773, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1458 1110 1480 1128\n",
      "tensor(58800, device='cuda:0') 1.0 tensor(0.5186, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1129 1095 1151 1111\n",
      "tensor(57956, device='cuda:0') 1.0 tensor(0.4985, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1128 1096 1152 1112\n",
      "tensor(58801, device='cuda:0') 0.9921875 tensor(0.5063, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1310 1097 1332 1113\n",
      "tensor(57957, device='cuda:0') 1.0 tensor(0.4956, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1312 1094 1334 1110\n",
      "tensor(58802, device='cuda:0') 1.0 tensor(0.4778, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1460 1094 1480 1112\n",
      "tensor(57958, device='cuda:0') 1.0 tensor(0.4895, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1458 1093 1480 1111\n",
      "tensor(58914, device='cuda:0') 0.83447265625 tensor(0.6118, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 916 558 1014 576\n",
      "tensor(58070, device='cuda:0') 1.0 tensor(0.6689, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 911 560 1011 578\n",
      "tensor(58915, device='cuda:0') 0.99951171875 tensor(0.6143, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1147 559 1233 575\n",
      "tensor(58071, device='cuda:0') 1.0 tensor(0.6743, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1154 563 1240 581\n",
      "tensor(58916, device='cuda:0') 1.0 tensor(0.6392, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1345 562 1431 580\n",
      "tensor(58072, device='cuda:0') 1.0 tensor(0.6626, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1347 567 1429 585\n",
      "tensor(58917, device='cuda:0') 1.0 tensor(0.4771, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 900 454 962 474\n",
      "tensor(58073, device='cuda:0') 1.0 tensor(0.6294, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 890 456 946 476\n",
      "tensor(58917, device='cuda:0') 1.0 tensor(0.2805, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 866 451 942 473\n",
      "tensor(58073, device='cuda:0') 1.0 tensor(0.5986, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1112 458 1168 476\n",
      "tensor(58959, device='cuda:0') 4.589557647705078e-05 tensor(0.2742, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1137 870 1165 892\n",
      "tensor(59058, device='cuda:0') 0.99755859375 tensor(0.0446, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1171 806 1217 832\n",
      "tensor(58214, device='cuda:0') 1.0 tensor(0.5928, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1130 662 1160 676\n",
      "tensor(59059, device='cuda:0') 1.0 tensor(0.5640, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1310 660 1338 674\n",
      "tensor(58215, device='cuda:0') 1.0 tensor(0.5898, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1309 662 1339 678\n",
      "tensor(59060, device='cuda:0') 1.0 tensor(0.5337, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1460 663 1486 679\n",
      "tensor(58216, device='cuda:0') 1.0 tensor(0.5586, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1457 659 1483 675\n",
      "tensor(59070, device='cuda:0') 0.98974609375 tensor(0.6802, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 158 358 788 478\n",
      "tensor(58226, device='cuda:0') 1.0 tensor(0.8047, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 166 381 752 487\n",
      "tensor(59196, device='cuda:0') 0.99951171875 tensor(0.5303, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1132 714 1158 728\n",
      "tensor(58352, device='cuda:0') 1.0 tensor(0.5898, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1133 713 1163 727\n",
      "tensor(59197, device='cuda:0') 1.0 tensor(0.5630, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1310 711 1336 727\n",
      "tensor(58353, device='cuda:0') 1.0 tensor(0.5796, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1310 713 1338 729\n",
      "tensor(59198, device='cuda:0') 1.0 tensor(0.5596, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1456 714 1482 730\n",
      "tensor(58354, device='cuda:0') 1.0 tensor(0.5713, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1454 714 1484 730\n",
      "tensor(59199, device='cuda:0') 1.0 tensor(0.5781, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1130 644 1160 658\n",
      "tensor(58355, device='cuda:0') 1.0 tensor(0.5728, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1126 644 1156 658\n",
      "tensor(59200, device='cuda:0') 1.0 tensor(0.5703, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1309 644 1339 658\n",
      "tensor(58356, device='cuda:0') 1.0 tensor(0.5791, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1308 643 1338 659\n",
      "tensor(59201, device='cuda:0') 1.0 tensor(0.5708, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1458 644 1486 660\n",
      "tensor(58357, device='cuda:0') 0.99755859375 tensor(0.5664, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1454 644 1482 660\n",
      "tensor(57856, device='cuda:0') 1.0 tensor(0.0118, device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 1015 761 1127 809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "mean = torch.Tensor(IMAGENET_DEFAULT_MEAN).reshape(3,1,1)\n",
    "std = torch.Tensor(IMAGENET_DEFAULT_STD).reshape(3,1,1)\n",
    "\n",
    "vsize = model.decoder.tokenizer.vocab_size + 1\n",
    "_img = model.encoder.prepare_input(image)\n",
    "_img = ((_img*std+mean)*255).permute(1,2,0).numpy().astype(np.uint8)\n",
    "_img = _img.copy()\n",
    "tkns = outs['tokens'][:,1:]\n",
    "scores = outs['scores'][1:]\n",
    "# idxs = [19,21]\n",
    "idxs = [ii for ii in range(len(scores))]\n",
    "_boxes = [boxes[0,ii] for ii in idxs]\n",
    "_tkns = [tkns[0,ii] for ii in idxs]\n",
    "_scores = [scores[ii] for ii in idxs]\n",
    "_confs = [confs[0,ii] for ii in idxs]\n",
    "# _boxes = boxes\n",
    "for box, tt, ss, cc in zip(_boxes,_tkns,_scores,_confs):\n",
    "# for box in _boxes:\n",
    "    if tt < vsize:\n",
    "        continue\n",
    "    x0 = box[0] - box[2]//2\n",
    "    y0 = box[1] - box[3]//2\n",
    "    x1 = box[0] + box[2]//2\n",
    "    y1 = box[1] + box[3]//2\n",
    "    print(tt,ss,cc, x0,y0,x1,y1)\n",
    "    # print(x0,y0,x1,y1)\n",
    "    cv2.rectangle(_img, (x0,y0),(x1,y1),(0,255,0),2)\n",
    "cv2.imwrite('hoge1.jpg',_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "import importlib\n",
    "importlib.reload(donut.model_custom)\n",
    "token_indexes = [41]\n",
    "decoder_cross_attentions = outs[\"attentions\"][\"cross_attentions\"]\n",
    "mean = torch.Tensor(IMAGENET_DEFAULT_MEAN).reshape(3,1,1)\n",
    "std = torch.Tensor(IMAGENET_DEFAULT_STD).reshape(3,1,1)\n",
    "\n",
    "box, thres_heatmap, agg_heatmap = donut.model_custom.DonutModel.max_bbox_from_heatmap(decoder_cross_attentions, token_indexes, discard_ratio=0, return_thres_agg_heatmap=True, final_h=1600,final_w=1600,heatmap_h=1600//32,heatmap_w=1600//32)\n",
    "_img = model.encoder.prepare_input(image)\n",
    "_img = ((_img*std+mean)*255).permute(1,2,0).numpy().astype(np.uint8)\n",
    "\n",
    "hmap = cv2.applyColorMap(agg_heatmap, cv2.COLORMAP_JET)\n",
    "viz = cv2.addWeighted(_img, 0.5, hmap, 0.5, 0)\n",
    "cv2.imwrite('hoge.jpg',viz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'segmap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39m# attens = cv2.resize(attens, None, None, fx=8, fy=8, interpolation=cv2.INTER_NEAREST)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m attens \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(attens, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, fx\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, fy\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, interpolation\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mINTER_NEAREST)\n\u001b[0;32m---> 26\u001b[0m seg_map \u001b[39m=\u001b[39m outs[\u001b[39m'\u001b[39;49m\u001b[39msegmap\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     27\u001b[0m cv2\u001b[39m.\u001b[39mimwrite(\u001b[39m'\u001b[39m\u001b[39msegmap.jpg\u001b[39m\u001b[39m'\u001b[39m, seg_map\u001b[39m*\u001b[39m\u001b[39m255\u001b[39m)\n\u001b[1;32m     29\u001b[0m seg_map \u001b[39m=\u001b[39m seg_map\u001b[39m*\u001b[39mattens\n",
      "\u001b[0;31mKeyError\u001b[0m: 'segmap'"
     ]
    }
   ],
   "source": [
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "mean = torch.Tensor(IMAGENET_DEFAULT_MEAN).reshape(3,1,1)\n",
    "std = torch.Tensor(IMAGENET_DEFAULT_STD).reshape(3,1,1)\n",
    "\n",
    "_img = model.encoder.prepare_input(image)\n",
    "_img = ((_img*std+mean)*255).permute(1,2,0).numpy().astype(np.uint8)\n",
    "hh, ww = _img.shape[0]//32, _img.shape[1]//32\n",
    "\n",
    "decoder_cross_attentions = outs[\"attentions\"][\"cross_attentions\"]\n",
    "token_indexes = [73]\n",
    "\n",
    "# attens = [decoder_cross_attentions[ii][-1].squeeze() for ii in token_indexes]\n",
    "# attens = torch.stack(attens).max(dim=0)[0].max(dim=0)[0]\n",
    "# attens = attens.reshape(_img.shape[0]//32, _img.shape[1]//32).detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "attens = [decoder_cross_attentions[ii][-1] for ii in token_indexes]\n",
    "attens = torch.stack(attens).squeeze(3)\n",
    "attens = attens.permute(1,2,0,3)\n",
    "attens = attens.reshape(1,16,-1,hh,ww).max(dim=2)[0]\n",
    "attens = torch.pixel_shuffle(attens,4)[0,0].detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "cv2.imwrite('attens.jpg', attens*255)\n",
    "# attens = cv2.resize(attens, None, None, fx=8, fy=8, interpolation=cv2.INTER_NEAREST)\n",
    "attens = cv2.resize(attens, None, None, fx=2, fy=2, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "seg_map = outs['segmap'].detach().cpu().numpy().squeeze().astype(np.float32)\n",
    "cv2.imwrite('segmap.jpg', seg_map*255)\n",
    "\n",
    "seg_map = seg_map*attens\n",
    "cv2.imwrite('score.jpg', seg_map*255)\n",
    "\n",
    "# seg_map = np.tile(seg_map[:,:,np.newaxis], (1,1,3))\n",
    "seg_map = cv2.resize(attens, None, fx=4, fy=4, interpolation=cv2.INTER_NEAREST)\n",
    "seg_map = cv2.applyColorMap((seg_map*255).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "\n",
    "hoge = cv2.addWeighted(_img, 0.5, seg_map, 0.5, 0)\n",
    "cv2.imwrite('viz.jpg', hoge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = outs['last_hidden_state']\n",
    "token_indexes = [123, 124, 125]\n",
    "\n",
    "attens = [outs['attentions']['cross_attentions'][ii][-1] for ii in token_indexes]\n",
    "#attens = [decoder_cross_attentions[ii][-1] for ii in range(len(decoder_cross_attentions))]\n",
    "attens = torch.stack(attens).squeeze(3)\n",
    "attens = attens.permute(1,2,0,3)\n",
    "mask = torch.where(attens<0.5)\n",
    "attens[mask]=0\n",
    "seg = model.forward_seg_head(enc, attens).sigmoid()[0,0]\n",
    "seg = seg.detach().cpu().numpy().astype(np.float32)*255\n",
    "seg=cv2.resize(seg, None, fx=4, fy=4, interpolation=cv2.INTER_NEAREST)\n",
    "seg = cv2.applyColorMap(seg.astype(np.uint8), cv2.COLORMAP_JET)\n",
    "hoge = cv2.addWeighted(_img, 0.5, seg, 0.5, 0)\n",
    "cv2.imwrite('hoge.jpg', hoge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "decode() missing 1 required positional argument: 'token_confs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39msuper\u001b[39;49m(BARTCustomTokenizer,model\u001b[39m.\u001b[39;49mdecoder\u001b[39m.\u001b[39;49mtokenizer)\u001b[39m.\u001b[39;49mbatch_decode(outs[\u001b[39m'\u001b[39;49m\u001b[39mtokens\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:3429\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_decode\u001b[0;34m(self, sequences, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3406\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbatch_decode\u001b[39m(\n\u001b[1;32m   3407\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   3408\u001b[0m     sequences: Union[List[\u001b[39mint\u001b[39m], List[List[\u001b[39mint\u001b[39m]], \u001b[39m\"\u001b[39m\u001b[39mnp.ndarray\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtorch.Tensor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtf.Tensor\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3411\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m   3412\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mstr\u001b[39m]:\n\u001b[1;32m   3413\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3414\u001b[0m \u001b[39m    Convert a list of lists of token ids into a list of strings by calling decode.\u001b[39;00m\n\u001b[1;32m   3415\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3427\u001b[0m \u001b[39m        `List[str]`: The list of decoded sentences.\u001b[39;00m\n\u001b[1;32m   3428\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3429\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m   3430\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecode(\n\u001b[1;32m   3431\u001b[0m             seq,\n\u001b[1;32m   3432\u001b[0m             skip_special_tokens\u001b[39m=\u001b[39mskip_special_tokens,\n\u001b[1;32m   3433\u001b[0m             clean_up_tokenization_spaces\u001b[39m=\u001b[39mclean_up_tokenization_spaces,\n\u001b[1;32m   3434\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   3435\u001b[0m         )\n\u001b[1;32m   3436\u001b[0m         \u001b[39mfor\u001b[39;00m seq \u001b[39min\u001b[39;00m sequences\n\u001b[1;32m   3437\u001b[0m     ]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:3430\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3406\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbatch_decode\u001b[39m(\n\u001b[1;32m   3407\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   3408\u001b[0m     sequences: Union[List[\u001b[39mint\u001b[39m], List[List[\u001b[39mint\u001b[39m]], \u001b[39m\"\u001b[39m\u001b[39mnp.ndarray\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtorch.Tensor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtf.Tensor\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3411\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m   3412\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mstr\u001b[39m]:\n\u001b[1;32m   3413\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3414\u001b[0m \u001b[39m    Convert a list of lists of token ids into a list of strings by calling decode.\u001b[39;00m\n\u001b[1;32m   3415\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3427\u001b[0m \u001b[39m        `List[str]`: The list of decoded sentences.\u001b[39;00m\n\u001b[1;32m   3428\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   3429\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m-> 3430\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecode(\n\u001b[1;32m   3431\u001b[0m             seq,\n\u001b[1;32m   3432\u001b[0m             skip_special_tokens\u001b[39m=\u001b[39;49mskip_special_tokens,\n\u001b[1;32m   3433\u001b[0m             clean_up_tokenization_spaces\u001b[39m=\u001b[39;49mclean_up_tokenization_spaces,\n\u001b[1;32m   3434\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   3435\u001b[0m         )\n\u001b[1;32m   3436\u001b[0m         \u001b[39mfor\u001b[39;00m seq \u001b[39min\u001b[39;00m sequences\n\u001b[1;32m   3437\u001b[0m     ]\n",
      "\u001b[0;31mTypeError\u001b[0m: decode() missing 1 required positional argument: 'token_confs'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5415e-01, 4.1237e-03, 1.6699e-03, 8.2350e-04, 2.3880e-03, 6.2764e-05,\n",
       "        8.3447e-04, 5.2214e-05, 1.0192e-04, 8.3113e-04, 9.4235e-05, 6.9666e-04,\n",
       "        1.9729e-05, 8.7142e-05, 1.3008e-03, 5.2261e-03, 3.7651e-03, 4.6396e-04,\n",
       "        1.9588e-03, 7.1168e-05, 8.5354e-04, 1.0031e-04, 8.0681e-04, 1.4365e-05,\n",
       "        5.7745e-04, 2.1243e-04, 3.4828e-03, 8.0156e-04, 3.2711e-03, 5.5981e-04,\n",
       "        7.2327e-03, 1.0681e-04, 6.8760e-04, 8.8573e-05, 1.0271e-03, 4.4966e-04,\n",
       "        4.9896e-03, 1.0614e-03, 1.4534e-03, 2.5392e-05, 7.4148e-04, 4.6432e-05,\n",
       "        2.1756e-04, 4.1187e-05, 2.7704e-04, 1.7881e-04, 1.1482e-03, 2.0466e-03,\n",
       "        3.1700e-03, 4.9400e-04, 4.6611e-04, 3.2377e-04, 3.3741e-03, 4.0829e-05,\n",
       "        2.4872e-03, 4.2000e-03, 1.3985e-02, 2.3937e-03, 2.2297e-03, 2.3193e-03,\n",
       "        1.6098e-02, 2.2831e-03, 2.4834e-03, 1.1129e-03, 7.5417e-03, 1.1629e-04,\n",
       "        1.2887e-04, 4.1187e-05, 4.2248e-04, 8.7142e-05, 1.3418e-03, 2.9707e-04,\n",
       "        1.3771e-02, 1.8063e-03, 9.4318e-04, 8.3208e-05, 1.1597e-02, 7.3338e-04,\n",
       "        4.3809e-05, 4.5609e-04, 5.8472e-05, 8.8978e-04, 4.8161e-05, 2.0587e-04,\n",
       "        1.3936e-04, 2.5654e-03, 6.6071e-03, 5.1178e-02, 3.7651e-03, 2.6894e-03,\n",
       "        9.8133e-04, 5.2643e-03, 6.6471e-04, 3.7289e-04, 2.4629e-04, 1.2094e-04,\n",
       "        1.3089e-04, 4.3583e-04, 1.1033e-04, 9.5069e-05, 1.4067e-04, 7.8201e-05,\n",
       "        9.4175e-05, 3.3426e-04, 7.3314e-05, 3.8445e-05, 1.7869e-04, 5.5134e-05,\n",
       "        1.6510e-05, 9.7275e-05, 1.5914e-05, 3.0041e-04, 3.8445e-05, 4.2856e-05,\n",
       "        1.3292e-04, 8.1360e-05, 8.2207e-04, 4.6196e-03, 6.8298e-02, 7.8249e-04,\n",
       "        1.4893e-02, 2.7227e-04, 1.8921e-03, 5.2223e-03, 1.3328e-04, 1.3838e-03,\n",
       "        8.8196e-03, 6.3324e-04, 4.2648e-03, 2.9278e-04, 1.4257e-03, 3.4833e-04,\n",
       "        5.4741e-04, 2.4176e-04, 5.1651e-03, 6.4898e-04, 5.3619e-02, 1.0624e-03,\n",
       "        4.3225e-04, 1.2189e-04, 1.7071e-04, 3.0899e-04, 1.4515e-03, 1.2627e-02,\n",
       "        1.1367e-04, 1.5854e-02, 4.3929e-05, 1.4138e-04, 6.7294e-05, 1.6868e-05,\n",
       "        3.0100e-05, 2.1577e-04, 3.0727e-03, 1.1086e-05, 6.5041e-03, 4.1187e-05,\n",
       "        3.1054e-05, 1.4067e-05, 2.5749e-05, 1.9729e-05, 9.2804e-05, 2.9507e-03,\n",
       "        7.1907e-04, 4.2648e-03, 4.3273e-04, 6.2943e-05, 4.3273e-05, 1.6534e-04,\n",
       "        1.3103e-03, 7.4339e-04, 2.5082e-03, 8.3590e-04, 1.2517e-04, 1.1533e-04,\n",
       "        1.9026e-04, 7.2050e-04, 4.2939e-04, 5.8327e-03, 1.2636e-04, 1.4114e-03,\n",
       "        1.5326e-03, 3.3207e-03, 7.5388e-04, 6.7253e-03, 4.4942e-04, 5.9242e-03,\n",
       "        2.0444e-04, 1.3280e-04, 9.6655e-04, 2.1782e-03, 2.0730e-04, 2.8992e-03,\n",
       "        2.1267e-03, 1.5686e-02, 4.8733e-04, 4.5013e-04, 2.3918e-03, 2.6054e-03,\n",
       "        1.7347e-03, 2.5864e-03, 6.2895e-04, 1.4515e-03, 5.9175e-04, 2.5845e-04,\n",
       "        3.9339e-05, 1.9956e-04, 1.3709e-04, 9.2773e-03, 2.0035e-02, 4.8828e-02,\n",
       "        4.9896e-03, 1.5701e-02, 3.1400e-04, 1.0929e-03, 3.7861e-04, 2.4662e-03,\n",
       "        4.8614e-04, 3.2711e-03, 1.6034e-04, 1.7672e-03, 6.9237e-03, 2.5330e-02,\n",
       "        6.2065e-03, 4.4403e-03, 2.6846e-04, 3.4752e-03, 5.6839e-04, 5.1041e-03,\n",
       "        2.8586e-04, 4.2648e-03, 3.2377e-04, 2.6001e-02, 8.8882e-03, 4.7333e-02,\n",
       "        1.4515e-03, 7.0143e-04, 1.7059e-04, 6.6817e-05, 6.5804e-05, 1.2417e-03,\n",
       "        8.6517e-03, 3.6955e-04, 4.1313e-03, 1.4377e-04, 1.4286e-03, 1.1539e-04,\n",
       "        3.0577e-05, 2.7835e-05, 2.5415e-04, 1.0786e-03, 1.1545e-04, 1.0138e-03,\n",
       "        7.6830e-05, 4.1127e-05, 1.7405e-05, 1.4544e-05, 7.4506e-06, 5.6267e-05,\n",
       "        1.1955e-02, 9.9945e-03, 3.0075e-02, 3.1400e-04, 1.0948e-03, 3.7551e-04,\n",
       "        2.3537e-03, 8.3389e-03, 7.5698e-05, 9.1982e-04, 4.8101e-05, 5.4538e-05,\n",
       "        2.3425e-05, 8.5115e-05, 3.1700e-03, 1.4246e-05, 4.8733e-04, 2.5153e-05,\n",
       "        8.0645e-05, 2.3127e-05, 9.4235e-05, 1.4206e-02, 1.9836e-03, 2.6321e-02,\n",
       "        3.6955e-04, 1.5114e-02, 2.3365e-03, 5.3062e-03, 5.7602e-03, 1.4937e-04,\n",
       "        1.1129e-03, 1.1623e-05, 3.8433e-04, 1.6403e-04, 2.9469e-04, 2.3708e-03,\n",
       "        1.4365e-05, 5.1594e-04, 1.4544e-05, 3.6359e-05, 2.1338e-05, 4.1842e-05,\n",
       "        1.4366e-02, 2.7542e-03, 5.7411e-03, 3.6693e-04, 2.3675e-04, 6.8903e-05,\n",
       "        7.5293e-04, 6.0120e-03, 3.8087e-05, 3.0899e-03, 4.3452e-05, 2.6226e-05,\n",
       "        1.7166e-05, 2.7180e-05, 4.7417e-03, 2.8729e-05, 1.4353e-03, 2.2769e-05,\n",
       "        7.2241e-05, 1.1981e-05, 5.1260e-05, 7.7209e-03, 4.5395e-03, 6.6071e-03,\n",
       "        1.9646e-04, 3.4189e-04, 7.0572e-05, 6.9666e-04, 5.5046e-03, 6.6817e-05,\n",
       "        1.8778e-03, 5.9605e-05, 3.5286e-05, 2.1696e-05, 5.2035e-05, 2.7008e-03,\n",
       "        2.1696e-05, 5.2404e-04, 3.6716e-05, 2.9027e-05, 1.2696e-05, 3.5763e-05,\n",
       "        2.0874e-02, 8.3542e-03, 2.2583e-02, 1.3618e-02, 3.6678e-03, 1.0788e-02,\n",
       "        4.8187e-02, 2.1572e-03, 1.1559e-02, 2.0370e-03, 6.8331e-04, 1.8110e-03,\n",
       "        1.0193e-02, 3.0851e-04, 1.6422e-03, 2.0180e-03, 4.2939e-04, 7.6628e-04,\n",
       "        3.1738e-02, 4.7333e-02, 1.7685e-02, 2.0466e-03, 1.4014e-01, 3.0160e-04,\n",
       "        7.2708e-03, 3.8743e-04, 1.3451e-02, 9.8348e-06, 2.7122e-03, 1.0794e-04,\n",
       "        5.2094e-02, 9.9754e-04, 3.5156e-02, 1.9257e-02, 5.6190e-03, 2.8563e-04,\n",
       "        1.0086e-02, 2.8858e-03, 3.6812e-03, 1.7464e-05, 1.7872e-03, 2.5797e-04,\n",
       "        2.5558e-02, 1.5961e-02, 2.3315e-02, 3.4580e-03, 5.8289e-03, 3.4256e-03,\n",
       "        2.4815e-03, 4.2953e-03, 2.3407e-02, 1.5649e-01, 2.3003e-03, 1.0925e-01,\n",
       "        7.3204e-03, 7.5531e-03, 1.5808e-02, 2.6779e-02, 1.1253e-02, 5.9052e-03,\n",
       "        4.5197e-02, 7.9918e-04, 1.5649e-01, 9.5825e-03, 2.6417e-03, 7.1526e-03,\n",
       "        1.8616e-02, 1.5650e-03, 1.2770e-03, 1.8445e-01, 8.1909e-02, 2.4231e-01,\n",
       "        2.0386e-02, 6.6943e-01, 3.0908e-01, 6.8994e-01, 8.4180e-01],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel=outs[\"attentions\"]['self_attentions'][418][-1]\n",
    "sel = sel.squeeze().max(dim=0)[0]\n",
    "sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 577, 1024])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_states = [ds[-1] for ds in outs[\"decoder_state\"]]\n",
    "decoder_states = torch.cat(decoder_states, dim=1)\n",
    "decoder_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
